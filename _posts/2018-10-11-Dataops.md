---
title: Dataops
subtitle: Clave para implementar BigData a nivel corporativo
excerpt: >-
  ¿Porqué es relevante conocer este concepto?. En la medida que los datos son más utilizados en la organización, la demanda por ellos irá en aumento, tanto los requerimientos por datos nuevos, como la mejora/modificación de procesos existentes será mayor...
date: '2018-10-11'
thumb_img_path: images/huemul_ciclocompleto_mini.png
content_img_path: images/huemul_ciclocompleto.png
layout: post
---

¿Porqué es relevante conocer este concepto?. En la medida que los datos son más utilizados en la organización, **la demanda por ellos irá en aumento**, tanto los requerimientos por datos nuevos, como la mejora/modificación de procesos existentes será mayor, y si queremos garantizar un time to market adecuado y evitar que las áreas de datos sean el cuello de botella, deberemos tener **procesos ágiles** que permitan construir procesos robustos y en ambientes productivos en poco tiempo, con lógicas de negocio cada vez más complejas, en estructuras de datos diversas, evitando duplicar datos y esfuerzos, y garantizando la calidad, seguridad y acceso a los datos. En resumen, se debe considerar:

* generar código automático para la extracción y transformación de datos, en función de la estrategia definida, clasificando adecuadamente los responsables de los datos, el nivel de seguridad y sensibilidad de cara a clientes.
* documentación de estos procesos en forma automática a partir de la codificación / definiciones.
* implementar procesos de calidad de datos en forma automática a partir de los requerimientos de usuarios / CDO.
* ejecución de planes de prueba automatizado para garantizar la calidad del entregable.
* deploy automático a producción, una vez que se hayan cumplido todos los pasos anteriores.
* Control de acceso a los datos "siempre vivo" para garantizar la confidencialidad.

![Dataops con Huemul](/images/huemul_ciclocompleto.png )

**DataOps** tiene por objetivo mejorar la calidad de los procesos relacionados a la gestión de información, implementado código, controles y seguimiento automatizados para mejorar el ciclo de vida del desarrollo de procesos de datos. Es el equivalente de implementar DevOps en el desarrollo de soluciones digitales


## Definiciones

Wikipedia lo define como “un conjunto de prácticas y herramientas utilizadas por los equipos de Big Data para **aumentar la velocidad, la fiabilidad y la calidad** del análisis de datos” [wikipedia.org/wiki/Dataops)](https://en.wikipedia.org/wiki/Dataops), mientras que Gartner lo define como un **centro de recolección y distribución de datos**, con el mandato de proporcionar acceso controlado a los registros, protegiendo la privacidad de los datos de clientes, restricciones de uso e integridad de datos [www.gartner.com/it-glossary/data-ops](http://www.gartner.com/it-glossary/data-ops). Más amplia es la definición que entrega SearchDataManagement, la menciona como una **estrategia inspirada en DevOps** (practicas relacionadas a la integración continua en el desarrollo de software), y que busca  **romper los silos entre las áreas de TI y desarrollo**, alentando a las áreas de Data Engineering y Data Scientist para que los datos de la organización puedan utilizarse de manera más flexible y efectiva posible para lograr resultados positivos en los negocios [searchdatamanagement.techtarget.com/definition/DataOps](http://searchdatamanagement.techtarget.com/definition/DataOps). SAS, por su parte, identifica seis desafíos claves relacionados con Data Engineering, data quality, actualizaciones, integración de datos e inteoperatividad, privacidad de datos y seguridad de la información [blogs.sas.com/content/datamanagement/2016/07/14/data-ops-data-prep-analytics-iot](http://blogs.sas.com/content/datamanagement/2016/07/14/data-ops-data-prep-analytics-iot).

## Resumen
Todas las fuente consultadas concuerdan en que no existen software que permitan construir un ambiente basado en DataOps, sino que este concepto se implementa en la forma de un framework apoyado por algunas herramientas específicas para el control de los procesos y cumplimiento de las seis áreas claves señaladas anteriormente, el foco es aumentar la colaboración entre las distintas áreas que utilizan los datos y mejorar la agilidad en el acceso a la información, todo ello bajo un control adecuado que asegure la calidad de la información y con el correcto control de acceso.

